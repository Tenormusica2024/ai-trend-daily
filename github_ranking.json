{
  "updated_at": "2026-01-24 09:00:40",
  "total_repos": 13,
  "ranking": [
    {
      "rank": 1,
      "repo_name": "remotion-dev/remotion",
      "description": "üé• Make videos programmatically with React",
      "description_ja": "üé• Make videos programmatically with React",
      "readme_summary": "<p align=\"center\"> <a href=\"https://github.com/remotion-dev/logo\"> <picture> <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\"> <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\"> </picture> </a> </p> ![Discord Shield](https://remotion.dev/discord) ![NPM Version](https://www.npmjs.org/package/remotion) ![NPM Downloads](https://npmcharts.com/compare/re...",
      "readme_summary_ja": "<p align=\"center\"> <a href=\"https://github.com/remotion-dev/logo\"> <picture> <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-dark.apng\"> <img alt=\"Animated Remotion Logo\" src=\"https://github.com/remotion-dev/logo/raw/main/animated-logo-banner-light.gif\"> </picture> </a> </p> ![Discord Shield](https://remotion.dev/discord) ![NPM Version](https://www.npmjs.org/package/remotion) ![NPM Downloads](https://npmcharts.com/compare/re...",
      "language": "TypeScript",
      "stars": 1618
    },
    {
      "rank": 2,
      "repo_name": "microsoft/VibeVoice",
      "description": "Open-Source Frontier Voice AI",
      "description_ja": "Open-Source Frontier Voice AI",
      "readme_summary": "<div align=\"center\"> üéôÔ∏è VibeVoice: Open-Source Frontier Voice AI ![Project Page](https://microsoft.github.io/VibeVoice) ![Hugging Face](https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f) ![TTS Report](https://arxiv.org/pdf/2508.19205) ![Colab](https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/VibeVoice_colab.ipynb) ![ASR Playground](https://aka.ms/vibevoice-asr) </div> <div align=\"center\"> <picture> <source media=\"(prefers-color-scheme: dar...",
      "readme_summary_ja": "<div align=\"center\"> üéôÔ∏è VibeVoice: Open-Source Frontier Voice AI ![Project Page](https://microsoft.github.io/VibeVoice) ![Hugging Face](https://huggingface.co/collections/microsoft/vibevoice-68a2ef24a875c44be47b034f) ![TTS Report](https://arxiv.org/pdf/2508.19205) ![Colab](https://colab.research.google.com/github/microsoft/VibeVoice/blob/main/demo/VibeVoice_colab.ipynb) ![ASR Playground](https://aka.ms/vibevoice-asr) </div> <div align=\"center\"> <picture> <source media=\"(prefers-color-scheme: dar...",
      "language": "Python",
      "stars": 261
    },
    {
      "rank": 3,
      "repo_name": "block/goose",
      "description": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "description_ja": "an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM",
      "readme_summary": "<div align=\"center\"> goose _a local, extensible, open source AI agent that automates engineering tasks_ <p align=\"center\"> <a href=\"https://opensource.org/licenses/Apache-2.0\"> <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\"> </a> <a href=\"https://discord.gg/goose-oss\"> <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\"> </a> <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\"> ...",
      "readme_summary_ja": "<div align=\"center\"> goose _a local, extensible, open source AI agent that automates engineering tasks_ <p align=\"center\"> <a href=\"https://opensource.org/licenses/Apache-2.0\"> <img src=\"https://img.shields.io/badge/License-Apache_2.0-blue.svg\"> </a> <a href=\"https://discord.gg/goose-oss\"> <img src=\"https://img.shields.io/discord/1287729918100246654?logo=discord&logoColor=white&label=Join+Us&color=blueviolet\" alt=\"Discord\"> </a> <a href=\"https://github.com/block/goose/actions/workflows/ci.yml\"> ...",
      "language": "Rust",
      "stars": 491
    },
    {
      "rank": 4,
      "repo_name": "ai-dynamo/dynamo",
      "description": "A Datacenter Scale Distributed Inference Serving Framework",
      "description_ja": "A Datacenter Scale Distributed Inference Serving Framework",
      "readme_summary": "<!-- SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved. SPDX-License-Identifier: Apache-2.0 Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License",
      "readme_summary_ja": "<!-- SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION & AFFILIATES. All rights reserved. SPDX-License-Identifier: Apache-2.0 Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License",
      "language": "Rust",
      "stars": 33
    },
    {
      "rank": 5,
      "repo_name": "browser-use/browser-use",
      "description": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "description_ja": "üåê Make websites accessible for AI agents. Automate tasks online with ease.",
      "readme_summary": "<picture> <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24\"\"> <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/774a46d5-27a0-490c-b7d0-e65fcbbfa358\"> <img alt=\"Shows a black Browser Use Logo in light color mode and a white one in dark color mode.\" src=\"https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24\" width=\"full\"> </picture> <div alig...",
      "readme_summary_ja": "<picture> <source media=\"(prefers-color-scheme: light)\" srcset=\"https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24\"\"> <source media=\"(prefers-color-scheme: dark)\" srcset=\"https://github.com/user-attachments/assets/774a46d5-27a0-490c-b7d0-e65fcbbfa358\"> <img alt=\"Shows a black Browser Use Logo in light color mode and a white one in dark color mode.\" src=\"https://github.com/user-attachments/assets/2ccdb752-22fb-41c7-8948-857fc1ad7e24\" width=\"full\"> </picture> <div alig...",
      "language": "Python",
      "stars": 205
    },
    {
      "rank": 6,
      "repo_name": "github/copilot-cli",
      "description": "GitHub Copilot CLI brings the power of Copilot coding agent directly to your terminal.",
      "description_ja": "GitHub Copilot CLI brings the power of Copilot coding agent directly to your terminal.",
      "readme_summary": "GitHub Copilot CLI (Public Preview) The power of GitHub Copilot, now in your terminal. GitHub Copilot CLI brings AI-powered coding assistance directly to your command line, enabling you to build, debug, and understand code through natural language conversations. Powered by the same agentic harness as GitHub's Copilot coding agent, it provides intelligent assistance while staying deeply integrated with your GitHub workflow",
      "readme_summary_ja": "GitHub Copilot CLI (Public Preview) The power of GitHub Copilot, now in your terminal. GitHub Copilot CLI brings AI-powered coding assistance directly to your command line, enabling you to build, debug, and understand code through natural language conversations. Powered by the same agentic harness as GitHub's Copilot coding agent, it provides intelligent assistance while staying deeply integrated with your GitHub workflow",
      "language": "Shell",
      "stars": 125
    },
    {
      "rank": 7,
      "repo_name": "Asabeneh/30-Days-Of-Python",
      "description": "The 30 Days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than 100 days. Follow your own pace. These videos may help too:https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw",
      "description_ja": "The 30 Days of Python programming challenge is a step-by-step guide to learn the Python programming language in 30 days. This challenge may take more than 100 days. Follow your own pace. These videos may help too:https://www.youtube.com/channel/UC7PNRuno1rzYPb1xLa4yktw",
      "readme_summary": "üêç 30 Days Of Python |Day | Topics | |------|:---------------------------------------------------------:| | 01 | Introduction| | 02 | Variables, Built-in Functions| | 03 | Operators| | 04 | Strings| | 05 | Lists| | 06 | Tuples| | 07 | Sets| | 08 | Dictionaries| | 09 | Conditionals| | 10 | Loops| | 11 | Functions| | 12 | Modules| | 13 | List Comprehension| | 14 | Higher Order Functions| | 15 | Python Type Errors| | 16 | Python Date time | | 17 | Exception Handling| | 18 | Regular Expressions| | 19...",
      "readme_summary_ja": "üêç 30 Days Of Python |Day | Topics | |------|:---------------------------------------------------------:| | 01 | Introduction| | 02 | Variables, Built-in Functions| | 03 | Operators| | 04 | Strings| | 05 | Lists| | 06 | Tuples| | 07 | Sets| | 08 | Dictionaries| | 09 | Conditionals| | 10 | Loops| | 11 | Functions| | 12 | Modules| | 13 | List Comprehension| | 14 | Higher Order Functions| | 15 | Python Type Errors| | 16 | Python Date time | | 17 | Exception Handling| | 18 | Regular Expressions| | 19...",
      "language": "Python",
      "stars": 91
    },
    {
      "rank": 8,
      "repo_name": "anthropics/claude-code",
      "description": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "description_ja": "Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows - all through natural language commands.",
      "readme_summary": "Claude Code ![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-code) [npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your ter...",
      "readme_summary_ja": "Claude Code ![](https://img.shields.io/badge/Node.js-18%2B-brightgreen?style=flat-square) [![npm]](https://www.npmjs.com/package/@anthropic-ai/claude-code) [npm]: https://img.shields.io/npm/v/@anthropic-ai/claude-code.svg?style=flat-square Claude Code is an agentic coding tool that lives in your terminal, understands your codebase, and helps you code faster by executing routine tasks, explaining complex code, and handling git workflows -- all through natural language commands. Use it in your ter...",
      "language": "Shell",
      "stars": 393
    },
    {
      "rank": 9,
      "repo_name": "deepseek-ai/FlashMLA",
      "description": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "description_ja": "FlashMLA: Efficient Multi-head Latent Attention Kernels",
      "readme_summary": "FlashMLA Introduction FlashMLA is DeepSeek's library of optimized attention kernels, powering the DeepSeek-V3 and DeepSeek-V3.2-Exp models. This repository contains the following implementations: **Sparse Attention Kernels** *These kernels power DeepSeek Sparse Attention (DSA), as introduced in this paper.* - Token-level sparse attention for the prefill stage - Token-level sparse attention for the decoding stage, with FP8 KV cache **Dense Attention Kernels** - Dense attention for the prefill sta...",
      "readme_summary_ja": "FlashMLA Introduction FlashMLA is DeepSeek's library of optimized attention kernels, powering the DeepSeek-V3 and DeepSeek-V3.2-Exp models. This repository contains the following implementations: **Sparse Attention Kernels** *These kernels power DeepSeek Sparse Attention (DSA), as introduced in this paper.* - Token-level sparse attention for the prefill stage - Token-level sparse attention for the decoding stage, with FP8 KV cache **Dense Attention Kernels** - Dense attention for the prefill sta...",
      "language": "C++",
      "stars": 184
    },
    {
      "rank": 10,
      "repo_name": "microsoft/Data-Science-For-Beginners",
      "description": "10 Weeks, 20 Lessons, Data Science for All!",
      "description_ja": "10 Weeks, 20 Lessons, Data Science for All!",
      "readme_summary": "Data Science for Beginners - A Curriculum ![Open in GitHub Codespaces](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=344191198) ![GitHub license](https://github.com/microsoft/Data-Science-For-Beginners/blob/master/LICENSE) ![GitHub contributors](https://GitHub.com/microsoft/Data-Science-For-Beginners/graphs/contributors/) ![GitHub issues](https://GitHub.com/microsoft/Data-Science-For-Beginners/issues/) ![GitHub pull-requests](https://GitHub.com/microsoft/Data-Science-For-...",
      "readme_summary_ja": "Data Science for Beginners - A Curriculum ![Open in GitHub Codespaces](https://github.com/codespaces/new?hide_repo_select=true&ref=main&repo=344191198) ![GitHub license](https://github.com/microsoft/Data-Science-For-Beginners/blob/master/LICENSE) ![GitHub contributors](https://GitHub.com/microsoft/Data-Science-For-Beginners/graphs/contributors/) ![GitHub issues](https://GitHub.com/microsoft/Data-Science-For-Beginners/issues/) ![GitHub pull-requests](https://GitHub.com/microsoft/Data-Science-For-...",
      "language": "Jupyter Notebook",
      "stars": 555
    },
    {
      "rank": 11,
      "repo_name": "OpenBMB/UltraRAG",
      "description": "UltraRAG v3: A Low-Code MCP Framework for Building Complex and Innovative RAG Pipelines",
      "description_ja": "UltraRAG v3: A Low-Code MCP Framework for Building Complex and Innovative RAG Pipelines",
      "readme_summary": "<p align=\"center\"> <picture> <source media=\"(prefers-color-scheme: dark)\" srcset=\"./docs/ultrarag_dark.svg\"> <source media=\"(prefers-color-scheme: light)\" srcset=\"./docs/ultrarag.svg\"> <img alt=\"UltraRAG\" src=\"./docs/ultrarag.svg\" width=\"55%\"> </picture> </p> <h3 align=\"center\"> Less Code, Lower Barrier, Faster Deployment </h3> <p align=\"center\"> | <a href=\"https://ultrarag.openbmb.cn/pages/en/getting_started/introduction\"><b>Documentation</b></a> | <a href=\"https://modelscope.cn/datasets/UltraR...",
      "readme_summary_ja": "<p align=\"center\"> <picture> <source media=\"(prefers-color-scheme: dark)\" srcset=\"./docs/ultrarag_dark.svg\"> <source media=\"(prefers-color-scheme: light)\" srcset=\"./docs/ultrarag.svg\"> <img alt=\"UltraRAG\" src=\"./docs/ultrarag.svg\" width=\"55%\"> </picture> </p> <h3 align=\"center\"> Less Code, Lower Barrier, Faster Deployment </h3> <p align=\"center\"> | <a href=\"https://ultrarag.openbmb.cn/pages/en/getting_started/introduction\"><b>Documentation</b></a> | <a href=\"https://modelscope.cn/datasets/UltraR...",
      "language": "Python",
      "stars": 130
    },
    {
      "rank": 12,
      "repo_name": "lyogavin/airllm",
      "description": "AirLLM 70B inference with single 4GB GPU",
      "description_ja": "AirLLM 70B inference with single 4GB GPU",
      "readme_summary": "!airllm_logo **Quickstart** | **Configurations** | **MacOS** | **Example notebooks** | **FAQ** **AirLLM** optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning. And you can run **405B Llama3.1** on **8GB vram** now. <a href=\"https://github.com/lyogavin/airllm/stargazers\">!GitHub Repo stars</a> ![Downloads](https://pepy.tech/project/airllm) ![Code License](https://github.com/LianjiaTech/BELLE/b...",
      "readme_summary_ja": "!airllm_logo **Quickstart** | **Configurations** | **MacOS** | **Example notebooks** | **FAQ** **AirLLM** optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card without quantization, distillation and pruning. And you can run **405B Llama3.1** on **8GB vram** now. <a href=\"https://github.com/lyogavin/airllm/stargazers\">!GitHub Repo stars</a> ![Downloads](https://pepy.tech/project/airllm) ![Code License](https://github.com/LianjiaTech/BELLE/b...",
      "language": "Jupyter Notebook",
      "stars": 493
    },
    {
      "rank": 13,
      "repo_name": "KellerJordan/modded-nanogpt",
      "description": "NanoGPT (124M) in 2 minutes",
      "description_ja": "NanoGPT (124M) in 2 minutes",
      "readme_summary": "Modded-NanoGPT This repository hosts the *NanoGPT speedrun*, in which we (collaboratively|competitively) search for the fastest algorithm to use 8 NVIDIA H100 GPUs to train a language model that attains 3.28 cross-entropy loss on the FineWeb validation set. The target (3.28 validation loss on FineWeb) follows Andrej Karpathy's GPT-2 replication in llm.c, which attains that loss after running for 45 minutes. The speedrun code also descends from llm.c's PyTorch trainer, which itself descends from ...",
      "readme_summary_ja": "Modded-NanoGPT This repository hosts the *NanoGPT speedrun*, in which we (collaboratively|competitively) search for the fastest algorithm to use 8 NVIDIA H100 GPUs to train a language model that attains 3.28 cross-entropy loss on the FineWeb validation set. The target (3.28 validation loss on FineWeb) follows Andrej Karpathy's GPT-2 replication in llm.c, which attains that loss after running for 45 minutes. The speedrun code also descends from llm.c's PyTorch trainer, which itself descends from ...",
      "language": "Python",
      "stars": 54
    }
  ]
}